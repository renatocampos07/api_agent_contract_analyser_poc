import json
import re
import sys
import io
from typing import List, Dict, Any, Optional
from app.analysis.prompts import get_clause_analysis_prompt
from app.analysis.llm_provider import get_chat_llm
from langchain_core.output_parsers import JsonOutputParser

# --- NOVO: PROMPT DO AGENTE RED TEAM (VERS√ÉO FINAL COM REALISMO E RENDI√á√ÉO) ---
RED_TEAM_SYSTEM_PROMPT = """
Voc√™ √© o **Advogado do Diabo**, especialista em "Red Teaming" de contratos corporativos.
Sua fun√ß√£o √© testar a robustez da Regra de Compliance, MAS mantendo os p√©s no ch√£o da realidade jur√≠dica.

ENTRADAS:
1. REGRA ATUAL: A l√≥gica que est√° sendo testada.
2. CL√ÅUSULA ALVO (USU√ÅRIO): O texto original.
3. STATUS DA DETEC√á√ÉO: Se a regra pegou ou n√£o o erro.
4. GROUND TRUTH: A pol√≠tica real da empresa.

---
### SUA MISS√ÉO
Tente encontrar uma brecha na Regra Atual criando uma **Cl√°usula Armadilha**.

**CEN√ÅRIO A (Ataque de Evas√£o):** Se a regra j√° detectou o erro do usu√°rio, tente criar uma varia√ß√£o do texto que mantenha o risco jur√≠dico mas **escape** da l√≥gica da regra (ex: usando sin√¥nimos complexos, mudando a estrutura frasal, escrevendo n√∫meros por extenso).
**CEN√ÅRIO B (Ataque de √ìbvio):** Se a regra N√ÉO detectou, crie um caso ainda mais gritante para provar a falha.
**CEN√ÅRIO C (RENDI√á√ÉO/APROVA√á√ÉO):**
Se voc√™ analisar a regra e concluir que ela √© **ROBUSTA**, cobrindo bem os sin√¥nimos e varia√ß√µes l√≥gicas sem ser r√≠gida demais, **N√ÉO INVENTE UM ATAQUE FOR√áADO**.
Admitir que o Engenheiro fez um bom trabalho √© parte da sua fun√ß√£o.

---
### üö´ RESTRI√á√ïES DE REALISMO (Anti-Alucina√ß√£o)
1. **Plausibilidade:** A cl√°usula armadilha deve parecer escrita por um advogado real ou um fornecedor tentando levar vantagem. N√£o crie textos po√©ticos ou informais.
2. **Contexto Jur√≠dico:** N√£o invente Leis, Artigos ou Decretos que n√£o existem. Use refer√™ncias gen√©ricas ("legisla√ß√£o aplic√°vel", "C√≥digo Civil") se necess√°rio.
3. **Foco no Risco:** Ataque a l√≥gica do risco (prazos, valores, responsabilidades).
4. **Evite "Edge Cases" Matem√°ticos:** N√£o use n√∫meros absurdos apenas para testar o limite da regra (ex: se o m√≠nimo √© 30 dias, **N√ÉO** use "29 dias"). Use prazos ruins comuns de mercado (ex: "5 dias", "imediato", "15 dias", "48 horas").

---
### SA√çDA OBRIGAT√ìRIA (JSON PURO)
{
    "raciocinio": "Explica√ß√£o t√©cnica da brecha encontrada (ou um elogio breve se a regra for aprovada).",
    "clausula_armadilha": "O texto da armadilha (ou escreva 'NENHUMA' se a regra for robusta)."
}
"""

def run_red_team_agent(llm, system_prompt, regra_atual, clausula_user, status_auditoria, ground_truth):
    """Executa o Agente Advers√°rio. (Assume que system_prompt j√° vem sanitizado com {{ }})."""
    try:
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import JsonOutputParser
        # Monta o template. O system_prompt j√° deve vir com chaves escapadas {{ }}.
        # As chaves {regra}, {clausula}, etc. no final s√£o as vari√°veis reais do LangChain.
        final_prompt_str = system_prompt + """
        \n--- DADOS DA RODADA ---
        REGRA ATUAL: {regra}
        CL√ÅUSULA ALVO (USU√ÅRIO): {clausula}
        STATUS DA DETEC√á√ÉO (USU√ÅRIO): {status}
        GROUND TRUTH: {ground_truth}
        """
        prompt = ChatPromptTemplate.from_template(final_prompt_str)
        chain = prompt | llm | JsonOutputParser()
        result = chain.invoke({
            "regra": regra_atual,
            "clausula": clausula_user,
            "status": status_auditoria,
            "ground_truth": ground_truth or "N√£o fornecido (Deduza pelo contexto)."
        })
        return result
    except Exception as e:
        print(f"‚ùå [RED TEAM ERRO] {str(e)}", flush=True)
        return None

# --- TEMPLATE REFATORADO COM TABELA E ESTRAT√âGIA GRADUAL ---
META_PROMPT_DEFAULT = """
### META PROMPT (JSON AGENT) ‚Äì RegraBuilder-AI

Voc√™ √© o **RegraBuilder-AI**, engenheiro especialista em regras para o "Rob√¥ Analisador JSON".
Sua fun√ß√£o √© refinar a **defini√ß√£o textual** de uma regra de compliance, ajustando-a conforme a fase da tentativa atual ({{tentativa_atual}} de {{max_tentativas}}).

**Restri√ß√£o de Integridade:**
Os campos `id_regra` (R0xx) e `nome` [T√≠tulo] s√£o chaves de identifica√ß√£o do sistema. **Voc√™ deve mant√™-los estritamente id√™nticos aos valores de entrada em todas as tentativas**, sem corre√ß√µes, expans√µes ou altera√ß√µes criativas. Sua evolu√ß√£o deve ocorrer exclusivamente no campo `descricao_prompt`.

O Agente que ler√° sua regra √© um ROB√î L√ìGICO E N√ÉO CONVERSACIONAL.
Ele precisa de instru√ß√µes do tipo: **"SE [condi√ß√£o no texto] ENT√ÉO [reporte erro] COM [recomenda√ß√£o]."**

---
### 1. ESTRAT√âGIA EVOLUTIVA (O Segredo do Ritmo)

#### Tentativas Iniciais (1 ‚Üí ~30%)
Estilo: **MACRO-ESTRUTURAL / (ESCOPO/CONCISA)**
Objetivo: Garantir que o contrato aborda o tema, sem validar detalhes finos.
‚Ä¢ **Mentalidade:** "A cl√°usula existe e faz sentido juridicamente?"
‚Ä¢ **Formato:** "Verifique a cl√°usula de [Objeto]. Se ela estiver ausente, vaga ou tratar de assunto divergente, reporte erro."
‚Ä¢ **O que evitar:** N√£o aplique restri√ß√µes num√©ricas r√≠gidas ou proibi√ß√µes de palavras espec√≠ficas nesta fase.

#### Tentativas Intermedi√°rias (~30% ‚Üí ~70%)
Estilo: **VALIDA√á√ÉO DE NEG√ìCIO (L√ìGICA/ELABORADA)**
Objetivo: Aplicar a regra de neg√≥cio (Golden Values).
‚Ä¢ **Mentalidade:** "A cl√°usula respeita os limites da empresa?"
‚Ä¢ **Formato:** "Analise os valores e condi√ß√µes. Se o prazo for inferior a [X] ou se a multa exceder [Y], reporte erro."
‚Ä¢ **A√ß√£o:** Agora insira os **n√∫meros-chave** e l√≥gicas de "Contratante vs Contratada".

#### Tentativas Finais (~70% ‚Üí 100%)
Estilo: **L√ìGICA LITERAL (OVERFITTING/EXAUSTIVA)**
Objetivo: Ca√ßa-palavras de toler√¢ncia zero.
‚Ä¢ **Mentalidade:** "O texto cont√©m a frase proibida exata?"
‚Ä¢ **Formato:** "ATEN√á√ÉO: Busque exatamente as strings [Frase 1] ou [Frase 2]. Se encontrar, reporte erro cr√≠tico imediatamente."
‚Ä¢ **A√ß√£o:** Hardcoding de termos do Ground Truth.

---
### 2. COMO PROCESSAR OS DADOS
1.  **Hist√≥rico:** Se a tentativa anterior falhou em detectar (Falso Negativo), avance a l√≥gica de "Estrutural" para "Valida√ß√£o de Valor".
2.  **Ground Truth:** Use para calibrar a severidade da recomenda√ß√£o no texto descritivo.
3.  **Cl√°usula Teste ({{exemplo_texto_original}}):** Use para testar mentalmente se sua l√≥gica "SE" seria ativada.

---
---
### 3. FORMATO OBRIGAT√ìRIO DE SA√çDA (JSON)

Voc√™ deve retornar **EXCLUSIVAMENTE** um objeto JSON.
O campo `descricao_prompt` deve conter a regra completa em texto corrido (sem Markdown, sem bullets).

'''
{
    "id_regra": "{{id_regra}}",
    "nome": "{{titulo_regra}}",
    "descricao_prompt": "Escreva aqui a defini√ß√£o l√≥gica da regra conforme a fase. Ex: 'Analise a cl√°usula de Pagamento. Se o prazo for inferior a 30 dias (ex. ilustrativo) ou omitido, reporte erro de Fluxo de Caixa. Recomenda√ß√£o: Ajustar para 30 dias (ex. ilustrativo).'"
}
'''

**Regras para o campo descricao_prompt:**
1.  Deve ser uma frase imperativa ou condicional.
2.  Deve incluir a **Condi√ß√£o de Erro** (Risco) e a **Recomenda√ß√£o** (A√ß√£o).
3.  N√£o use quebras de linha excessivas, o Rob√¥ JSON processa melhor par√°grafos densos.
4.  N√£o use estruturas A/B/C/D. Se houver m√∫ltiplas l√≥gicas, escreva: "Se X, erro A. Se Y, erro B." na mesma string.

### **4. DADOS BRUTOS**

Regra Atual:
{{json_rule}}

Hist√≥rico:
{{tabela_historico}}

Cl√°usula Teste:
{{exemplo_texto_original}}

Ground Truth:
{{exemplo_comentario}}

### **SUA SA√çDA: APENAS O JSON**
"""

def extrair_json_robusto(texto: str) -> str:
    """Encontra o primeiro '{' e o √∫ltimo '}' para isolar o JSON."""
    if not texto: return "{}"
    texto = texto.replace("```json", "").replace("```", "")
    idx_inicio = texto.find("{")
    idx_fim = texto.rfind("}")
    if idx_inicio != -1 and idx_fim != -1:
        return texto[idx_inicio : idx_fim + 1]
    return texto.strip()

def reverse_prompting_loop(
    system_prompt: str,
    rules_prompt: str,
    clausula_teste: str,
    exemplos_csv: str, 
    meta_prompt: str,
    max_attempts: int = 5,
    llm_deployment: Optional[str] = None,
    llm_temperature: Optional[float] = None,
    force_continue: bool = False,
    use_red_team: bool = False,
    red_team_prompt: str = '',
):
    # --- CONFIG DE CAPTURA DE LOGS ---
    log_capture_string = io.StringIO()
    class Tee(object):
        def __init__(self, *files): self.files = files
        def write(self, obj):
            for f in self.files: f.write(obj); f.flush()
        def flush(self):
            for f in self.files: f.flush()
    original_stdout = sys.stdout
    sys.stdout = Tee(sys.stdout, log_capture_string)

    try:
        # --- CONFIGURA√á√ÉO VISUAL ---
        # tr: usado apenas para resumos curtos de uma linha (status, regras curtas)
        tr = lambda s, l=150: str(s).replace('\n', ' ').replace('\r', '').strip()[:l] + "..." if len(str(s)) > l else str(s).replace('\n', ' ').strip()
        sep = f"\n   {'-'*60}" 

        # --- TRAVA DE SEGURAN√áA ---
        LIMITE_MAXIMO_BACKEND = 10
        if max_attempts > LIMITE_MAXIMO_BACKEND: max_attempts = LIMITE_MAXIMO_BACKEND

        tentativas = []
        red_team_alerts = []
        parser = JsonOutputParser()

        if not clausula_teste or not clausula_teste.strip():
            clausula_teste = "[ERRO: Cl√°usula vazia]"
        if not red_team_prompt or not red_team_prompt.strip():
            red_team_prompt = RED_TEAM_SYSTEM_PROMPT

        print(f"\nüîå [INIT] Conectando ao LLM...", flush=True)
        try:
            llm = get_chat_llm(llm_deployment, llm_temperature)
        except Exception as e:
            print(f"‚ùå [ERRO CR√çTICO] {str(e)}", flush=True)
            raise RuntimeError(f"Erro LLM: {str(e)}")

        meta_rule = None 
        metadados_regra = None

        print("\n" + "="*80)
        print(f"üöÄ INICIANDO PIPELINE DE REFINAMENTO (M√°x: {max_attempts})")
        print("="*80)

        for attempt in range(1, max_attempts + 1):
            print(f"\nüî∏ [TENTATIVA {attempt}/{max_attempts}] ================================================")

            # --- FASE 1: DEFINI√á√ÉO ---
            if attempt == 1:
                rules_current = rules_prompt.strip() or "Regra Gen√©rica"
                metadados_regra = {"origem": "Input Usu√°rio"}
            else:
                rules_current = meta_rule if meta_rule else rules_prompt
                metadados_regra = {"origem": "Meta Prompt"}

            # --- FASE 2: AUDITOR (An√°lise) ---
            print(sep)
            print(f"   üîç [AUDITOR] Analisando...", flush=True)
            
            rules_safe = rules_current.replace("{", "{{").replace("}", "}}")
            system_safe = system_prompt.replace("{", "{{").replace("}", "}}")
            red_team_safe = red_team_prompt.replace("{", "{{").replace("}", "}}")

            try:
                prompt_template = get_clause_analysis_prompt(rules_safe, parser, system_intro_override=system_safe)
                prompt_final = prompt_template.format_prompt(clausula_texto=clausula_teste).to_string()
                
                # LOG: Prompt com quebras reais
                print(f"      ‚û§ INPUT PROMPT COMPLETO:\n{prompt_final.strip()}\n")

                resp_obj = llm.invoke(prompt_final)
                resp_texto = resp_obj.content if hasattr(resp_obj, 'content') else str(resp_obj)
                
                resp_texto_clean = resp_texto.replace('```json', '').replace('```', '').strip()
                lista_erros: list[Any] = []
                try: data_resp = json.loads(resp_texto_clean)
                except: data_resp = None

                if isinstance(data_resp, dict):
                    if "erros" in data_resp and data_resp["erros"]: lista_erros = data_resp["erros"]
                    elif "comments" in data_resp and data_resp["comments"]: lista_erros = data_resp["comments"]
                    elif "error" in data_resp and data_resp["error"]: lista_erros = [data_resp["error"]]
                else:
                    if "erros" in resp_texto_clean.lower() and "[" in resp_texto_clean and not re.search(r'\[\s*\]', resp_texto_clean):
                        lista_erros = ["_json_broken_but_detected_"]

                icone_res = "‚úÖ DETECTOU" if lista_erros else "‚ùå PASSOU"
                print(f"      üìä DECIS√ÉO: {icone_res}")

            except Exception as e:
                print(f"      ‚ùå [ERRO AUDITOR] {e}", flush=True)
                resp_texto = "{}"
                lista_erros = []
                prompt_final = "Erro"

            status = "‚úÖ Detectou" if lista_erros else "‚ùå Falhou"
            tentativa_atual_dict = {
                "tentativa": attempt,
                "prompt_usado": prompt_final,
                "resposta_ia": resp_texto,
                "status": status,
                "regras_aplicadas_texto": rules_current,
                "regras_metadados": metadados_regra or {},
                "red_team_data": None
            }

            # --- FASE 3: RED TEAM (Desafiante) ---
            if use_red_team:
                print(sep)
                print(f"   ‚öîÔ∏è [DESAFIANTE] Testando robustez...", flush=True)
                status_logico = "DETECTOU" if lista_erros else "N√ÉO DETECTOU"
                
                # Monta visualmente o prompt (simula√ß√£o para log com quebras reais)
                debug_rt_prompt = red_team_safe + \
                    f"\n\n--- DADOS (INJETADOS) ---\nREGRA: {rules_current}\nCL√ÅUSULA: {clausula_teste}\nSTATUS: {status_logico}\nGROUND TRUTH: {exemplos_csv}"
                
                print(f"      ‚û§ INPUT PROMPT COMPLETO:\n{debug_rt_prompt.strip()}\n")

                attack_data = run_red_team_agent(
                    llm=llm,
                    system_prompt=red_team_safe,
                    regra_atual=rules_current,
                    clausula_user=clausula_teste,
                    status_auditoria=status_logico,
                    ground_truth=exemplos_csv
                )
                
                if attack_data:
                    clausula_arm = attack_data.get('clausula_armadilha', 'N/A')
                    if "NENHUMA" in clausula_arm.upper():
                        print(f"      üõ°Ô∏è DECIS√ÉO: REGRA APROVADA")
                    else:
                        print(f"      üí£ DECIS√ÉO: ATAQUE GERADO")

                    tentativa_atual_dict["red_team_data"] = attack_data
                    alert_msg = json.dumps(attack_data, ensure_ascii=False)
                    # CORRE√á√ÉO DE NOME NO HIST√ìRICO
                    red_team_alerts.append(f"Feedback Desafiante (T{attempt}): {alert_msg}")

            tentativas.append(tentativa_atual_dict)

            # --- FASE 4: DECIS√ÉO ---
            if lista_erros and not force_continue:
                print(f"\n‚ú® SUCESSO! Regra detectou o erro na tentativa {attempt}.", flush=True)
                break
            if attempt == max_attempts:
                print(f"\nüõë FIM (Limite alcan√ßado).", flush=True)
                break

            # --- FASE 5: ENGENHEIRO (Meta Prompt) ---
            print(sep)
            print(f"   üß† [ENGENHEIRO] Refinando regra...", flush=True)
            
            tabela_historico = ""
            for t in tentativas:
                tabela_historico += f"#### TENTATIVA {t['tentativa']} ({t['status']})\nRegra: {t['regras_aplicadas_texto']}\n---\n"
            
            # CORRE√á√ÉO DE NOME NO CABE√áALHO DO HIST√ìRICO
            if red_team_alerts:
                tabela_historico += "\n=== HIST√ìRICO DESAFIANTE ===\n" + "\n".join(red_team_alerts)

            exemplos_str = exemplos_csv if exemplos_csv else "Nenhum."
            
            meta_prompt_final = meta_prompt.replace("{{json_rule}}", rules_current) \
                .replace("{{exemplo_texto_original}}", clausula_teste) \
                .replace("{{tabela_historico}}", tabela_historico) \
                .replace("{{exemplo_comentario}}", exemplos_str) \
                .replace("{{tentativa_atual}}", str(attempt)) \
                .replace("{{max_tentativas}}", str(max_attempts))

            print(f"      ‚û§ INPUT PROMPT COMPLETO:\n{meta_prompt_final.strip()}\n")

            try:
                meta_resp = llm.invoke(meta_prompt_final)
                meta_raw = meta_resp.content if hasattr(meta_resp, 'content') else str(meta_resp)
                meta_clean = meta_raw.replace("```json", "").replace("```", "").strip()
                meta_rule = meta_clean
                
                # Output removido do log

            except Exception as e:
                print(f"      ‚ùå [ERRO ENGENHEIRO] {e}", flush=True)
                meta_rule = rules_current

    finally:
        sys.stdout = original_stdout
    
    logs_texto = log_capture_string.getvalue()
    log_capture_string.close()
    return tentativas, logs_texto